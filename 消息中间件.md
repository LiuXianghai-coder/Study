# 消息队列的优势

* 削峰填谷
* 系统耦合
* 提升性能
* 蓄流压测

# RocketMQ

相比较于 RabbitMQ、Kafka具有的主要优势：

- 支持事务型消息（消息发送和 DB 操作保持两方的最终一致性）
- 支持结合 RocketMQ 的多个系统之间数据的最终一致性（多方事务、二方事务是前提）
- 支持延时消息
- 支持指定次数和时间间隔的失败消息重发（Kafka 不支持，RabbitMQ 需手动确认）
- 支持 Consumer 端 tag 过滤，减少不必要的网络传输
- 支持重复消费（RabbitMQ 不支持）

### 架构

![img](https://rocketmq.apache.org/assets/images/rmq-basic-arc.png)

1. #### Name Server 集群
   
   ​    Name Server 提供一个轻量级的服务发现和路由，每个 Name Server 记录完整的路由信息，提供相应的读写服务，并且支持快速存储扩展。每个Name Server 之间无任何信息同步。
   
   ​    主要包含两个特点：Broker 管理、路由管理。

2. #### Broker 集群
   
   ​    Broker 通过提供轻量级的 TOPIC 和 QUEUE 机制来处理消息存储，它们支持 Push 和 Pull 模型，包含容错机制（2副本或3副本），并且提供强大的峰值填充和按照初始时间顺序积累数以千亿级别的消息的能力。除此之外，Brokers 提供了灾难恢复、丰富的指标统计和报警机制，这些都是传统消息传递系统所缺乏的。
   
   ​    Broker 分为Master 和 Slave，一个 Master 可以对应多个 Slave，但是一个 Slave 只能对应一个 Master， Master 和 Slave 的对应关系通过指定相同的 Broker Id， Broker Id 为 0 表示该  Broker 为 Master，非 0 表示该 Broker 为 Slave。
   
   ​    每个 Broker 与 Name Server 集群中的所有节点建立长连接，每隔 30s 注册 TOPIC 信息到所有的 Name Server。Name Server 每隔 10s 扫描所有存活的 Broker，如果 Name Server 超过两分钟没有收到来自 Broker 的心跳，则 Name Server 断开与 Broker 的的连接。 
   
   ​    Broker 负责消息的存储和交付、消息查询、高可用保障等。
   
   ​    ![img](https://rocketmq.apache.org/assets/images/rmq-basic-component.png)
   
   - Remoting Module: Broker 的进入点，负责处理来自客户端的请求
   
   - Client Manager: 管理客户端（Producer 和 Consumer）和维护 Consumer 的主题订阅
   
   - Store Service：提供简单的 API  用户存储或者查询在物理磁盘上的消息。
   
   - HA Service：提供在 Master Broker 和 Slave Broker 之间的数据同步特征
   
   - Index Service：通过指定的 key 来创建消息的索引，并且提供快速的消息查询。

3. #### Producer 集群
   
   ​    Producers 支持分布式部署，分布的 Producer 通过多种负载均衡方式发送消息到 Broker 集群。这个发送消息的进程支持快速失败并且具有低延迟。
   
   ​    Producer 与 Name Server 集群中的其中一个节点（随机选择）建立长连接，定期从 Name Server 获取所有 TOPIC 路由信息，并向提供 TOPIC 服务的 Master Broker 建立长连接，并且定时向 Master 发送心跳。Producer 完全无状态，可集群部署。
   
   ​    Producer 每隔 30s （由 ClientConfig 的 pollNameServerInterval）从 Name Server 获取所有 TOPIC 队列的最新情况，这意味着如果 Broker 不可用，Producer 最多 30s 内能够感知，在此期间发往 Broker 的所有消息都会失败。Producer 每隔 30s（由 ClientConfig 中的 heartBeatBrokerInterval决定）向所关联的 Broker 发送心跳，Broker 每隔 10s  扫描存活的连接，如果 Broker 在 2 分钟内没有收到心跳数据，则关闭与 Producer 的连接。

4. #### Consumer 集群
   
   ​    Consumer 支持 Push 模型和 Pull 模型的分布式部署，它也支持集群消费和信息广播。它提供实时的信息订阅机制并且可以满足大部分的 Consumer 需求。
   
   ​    Consumer 与 Name Server 集群中的其中一个节点（随机选择）建立长连接，定期从 Name Server 获取 TOPIC 的路由信息，并向提供 TOPIC 的 Broker 建立长连接，且定时向 Broker 发送心跳。
   
   ​    Consumer 既可以从 Master Broker 订阅消息，也可以从 Slave Broker 订阅消息，订阅规则由 Broker 配置决定。
   
   ​    Consumer 每隔 30s 从 Name Server 获取 TOPIC 的最新队列情况，这意味着当订阅的 Broker 不可用时，Consumer 最多需要 30s 才能感知。
   
   ​    Consumer 每隔 30s （由 ClientConfig 中 heartBeatBrokerInterval 决定）向所关联的 Broker 发送心跳，Broker 每隔 10s 扫描所有存活的连接，如果莫个连接 2 分钟内没有发送心跳数据，则关闭该连接，并向该 ConsumerGroup 的所有 Consumer 发送 通知，Group 内的 Consumer 重新分配额队列，然后继续消费。当 Consumer 得到 Master Broker 宕机的通知后，将会转向 Slave Broker 消费，Slave Broker 不能保证 Master Broker 的所有消息都会同步过来，因此会有少量的消息丢失。但是一旦 Master Broker 恢复过来之后，未同步的消息最终会被消费。
   
   ​    消费者队列是在消费者连接之后才有的，消费者标识为 {IP}@{ConsumerGroup}{TOPIC}{tag}，任何一个元素不同都被认为是不同的消费端，每个消费端会拥有自己的一份消费队列（默认是 Broker 队列数量 * Broker 数量）。

### 关键特性

1. #### 顺序消费
   
   按照消息的发送顺序来依次进行消费。RocketMQ 从业务的层面来保证消息的顺序，而不仅仅依靠消息系统。
   
   RocketMQ 通过轮询所有队列的方式来确定消息被发送到那一个队列（负载均衡策略）
   
   ```java
   // RocketMQ通过MessageQueueSelector中实现的算法来确定消息发送到哪一一个队列列上
   // RocketMQ默认提供了了两种MessageQueueSelector实现:随机/Hash
   // 当然你可以根据业务实现自自己己的MessageQueueSelector来决定消息按照何种策略略发送到消息队列列中
   SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
           @Override
           public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
               Integer id = (Integer) arg;
               int index = id % mqs.size(); // 对传入的参数 ID 对队列的大小进行取模，因此传入的参数 ID 一致的消息一定在同一队列
               return mqs.get(index);
           }
   }, orderId);
   ```
   
   获取到路由信息后，根据 MessageQueueSelector 实现的算法来选择一个队列。
   
   ```java
   private SendResult send() {
       // 获取topic路路由信息
       TopicPublishInfo topicPublishInfo =
       this.tryToFindTopicPublishInfo(msg.getTopic());
       if (topicPublishInfo != null && topicPublishInfo.ok()) {
           MessageQueue mq = null;
           // 根据我们的算法,选择一一个发送队列列
           // 这里里里的arg = orderId
           mq = selector.select(topicPublishInfo.getMessageQueueList(), msg, arg);
           if (mq != null) {
               return this.sendKernelImpl(msg, mq, communicationMode, sendCallback, timeout);
           }
       }
   }
   ```

2. #### 消息重复
   
   消息重复的根本原因：网络不可达
   
   处理：
   
   - 消费端处理消息的业务逻辑要保持幂等性
   - 保证每条数据都有唯一编号，且保证消息处理成功与去重表的日志同时出现

3. #### 事务消息
   
   RocketMQ 处理事务消息分为三个阶段：
   
   1. 第一阶段发送 Prepared 消息，拿到消息地址
   
   2. 执行本地事务
   
   3. 通过第一阶段拿到的地址去访问消息，并修改消息的状态
      
      生产者发送消息源代码：
      
      ```java
      TransactionCheckListener transactionCheckListener = new
      TransactionCheckListenerImpl();// 构造事务消息的生生产者
      TransactionMQProducer producer = new TransactionMQProducer("groupName");
      // 设置事务决断处理理类
      producer.setTransactionCheckListener(transactionCheckListener);
      // 本地事务的处理理逻辑,相当于示例例中检查Bob账户并扣钱的逻辑
      TransactionExecuterImpl tranExecuter = new TransactionExecuterImpl();
      producer.start()
      // 构造MSG,省略略构造参数
      Message msg = new Message(......);
      // 发送消息
      SendResult sendResult = producer.sendMessageInTransaction(msg, tranExecuter,
      null);
      producer.shutdown();
      ```
      
      `sendMessageInTransaction`源代码：
      
      ```java
      public TransactionSendResult sendMessageInTransaction(.....) {
          // 逻辑代码,非非实际代码
          // 1.发送消息
          sendResult = this.send(msg);
          // sendResult.getSendStatus() == SEND_OK
          // 2.如果消息发送成功,处理理与消息关联的本地事务单元
          if(sendResult.getStatus==SEND_OK)
          LocalTransactionState localTransactionState =
          tranExecuter.executeLocalTransactionBranch(msg, arg);
          // 3.结束事务
          this.endTransaction(sendResult, localTransactionState, localException);
      }
      ```
      
      ​    <img src="https://i.loli.net/2021/06/21/jkTD5w9uPLpR3N1.png" alt="2021-06-12 09-02-44 的屏幕截图.png" style="zoom:150%;" />

4. #### 消息存储
   
   RocketMQ的消息存储是由 `CommitQueue` 和 `CommitLog` 配合完成的。
   
   `ComsumeQueue`是消息的逻辑队列列,相当于字典的目目录,用用来指定消息在物理理文文件 `CommitLog`上的位
   置。
   
   - ##### CommitLog
     
     ​    每个 `TOPIC` 消息都存储在 CommitLog 的文件中，文件默认最大为 1 GB，超过 1 GB的内容将会写入下一个 CommitLog 文件中。RocketMQ采用顺序 IO 的方式写入磁盘，提高数据存储的性能。
     
     ​    消息在 CommitLog 文件中的存储格式如图所示：
     
     ![image-20210612091250513.png](https://i.loli.net/2021/06/21/Ows6VE48eQcIHN5.png)
   
   - ##### ComsumeQueue
     
     存储该消息队列中该 queue 在 CommitLog 中的 offset，具体结构如图所示：
     
     <img src="https://i.loli.net/2021/06/21/u54e3cAnMy9kZ7T.png" alt="image-20210612092249984.png" style="zoom:67%;" />

5. #### 消息存储方式
   
   ![image-20210612092436300.png](https://i.loli.net/2021/06/21/KuWJ9icsCLy5amI.png)
   
   ​    读取消息时，先读取 ComsumeQueue，得到对应的 offset，再从 CommitLog 中读取原始的消息。

6. #### 消息订阅
   
   RocketMQ 消息订阅存在两种模式：
   
   - push模式，MQServer 主动向消费端图送
   - pull 模式，消费端在需要时，主动从 MQServer 拉取。
   
   具体实现时，pull 模式和 push 模式都是消费端主动拉取的方式。
   
   消费端会通过 RebalanceService线程，10s 做一次基于 TOPIC 下的所有队列负载：

```
1. 遍历 Consumer 下所有的 TOPIC，根据 TOPIC 订阅所有的消息
2. 获取同一 TOPIC 和 Consume Group 下的所有 Consumer
3. 根据具体的分配策略来分配消费队列，分配的策略包含：平均分配、消费段配置等。
```

   消费端的 push 模式是通过长轮询来实现的，如图所示：

   ![image-20210612095515028.png](https://i.loli.net/2021/06/21/WKoMVFl3CTEr4IN.png)

   ​    消费端通过发送 pull 请求，如果有消息就立即将该消息发送给 Consumer，如果没有消息，则阻塞该请求。

7. #### RocketMQ 的最佳实践
   
   - Producer
     - 一个应用尽可能用一个 TOPIC，消息子类型用 tags 来标识，消费方在订阅消息时，可以使用 tags 进行过滤。
     - 每个消息在业务层面的唯一标识码，要设置到 keys 字段，方便将来定位消息丢失问题
     - 消息发送成功或者失败，要打印消息日志，务必打印 sendResult 和 key 字段
     - 对于消息不可丢失应用，务必要有消息重发机制。
   - Consumer
     - 消费过程要做到幂等
     - 尽量使用批量方式消费，可以很大程度上提高消费吞吐量
     - 优化每条消息的消费过程
   - 其他配置
     - 线上应当关闭 autoCreateEnable，即在配置文件中设置为 false

# Kafka

### 组件

​    ![image.png](https://i.loli.net/2021/06/21/letUjsIwCQcSgn3.png)

### 架构

![image-20210612122630202.png](https://i.loli.net/2021/06/21/594tKQuYOUTC2XZ.png)

### 重平衡

Kafka 重新组织 Topic 和 消费组中消费者的消费关系。

可能会引发重平衡机制的操作：

1. 消费组成员变更，有新的成员加入或者离开、或者崩溃

2. 消费组订阅的主题数量发生变更

3. 消费组订阅的分区数发生变更

### 生产消费

​    `request.required.acks = 0 -1 1`

### 日志存储

​    Kafka 的消息以主题为基本单位进行归类，TOPIC 作为逻辑上的概念，而 Partition  是物理上的概念。不考虑多副本的情况，一个分区对应一个日志（Log）。为了防止日志文件过大，Kafka 引入了日志分段（LogSegment），将 Log 分为多个 Segment。一般来讲，一个 LogSegment 包含 .log 日志文件、.index 偏移量索引文件、.timeindex 时间戳索引文件和一个 snapshot（快照）文件。

![image-20210612143931978.png](https://i.loli.net/2021/06/21/fx7oWbE62qItgjd.png)

### 分区副本

​    **Kafka 的副本机制是确保系统高可用和高持久的基石。**

​    对于每个 Broker 都有可能保存着各个主题下不同分区的副本，因此一个 Broker 上可能包含这上千个副本。

​    ![image.png](https://segmentfault.com/img/bVbHTjb)

#### Leader Replica

​    为了保证副本中的数据一致性，Kafka 的解决方案是领导者副本机制。如图所示：

​    ![image-20210612153515137.png](https://i.loli.net/2021/06/21/s8i2vRXzPYSIo5C.png)

- 在 Kafka 中，副本分为两类：Leader Replica 和 Follow Replica。每个 Partition 在创建时都要选取一个副本作为 Leader Replica，其余的所有副本成为 Follow Replica

- Kafka 中，Follow Replica 不对外提供服务，所有的请求都必须由 Leader Replica 来处理。Follow Replica 的任务是从 Leader Replica 中拉取消息，提交到自己的日志文件中，实现与 Leader Replica 的数据同步。

- 当 Leader Replica 所在的 Broker 挂掉之后，Kafka 通过 Zookeeper 提供的监控功能能够感知到，进行新一轮的 Leader Replica 选举。一般情况下，Kafka 的选举策略是按照副本的顺序来进行选择的。当老的 Leader Replica 恢复之后，只能作为 Follow Replica 存在。
  
  副本机制的好处：

- 方便实现 “Read-your—writes”。可以避免由于消息同步不及时导致的数据缺失问题，使用 Leader Replica 不会出现这样的问题。

- 方便实现“单调读”。由于多个副本的数据同步情况不一致，因此如果 Follow Replica 对外提供服务将会导致读取数据不一致的问题

#### ISR AR

​    ISR （In—Sync Replicas）：与 Leader Replica 同步的副本集合。ISR 不仅包括 Follow Replica，同时也包括 Leader Replica。

​    AR（All Replicas）：分区的所有副本集合。

​    判断一个分区副本是不是 ISR 中的副本，是通过该分区副本的同步数据情况落后于 Leader Replica 的最长时间来判断的，该阈值可以在 Broker 端中设置 replica.lag.time.max..ms 参数值来指定（默认为 10s）。如果一个 Follow Replica 的同步速度慢于 Leader Replica，那么在 replica.lag.time.max..ms 时间后，Kafka 将会收缩该 ISR 集合；如果被踢出的 Follow Leader 追上了 Leader Replica，那么将会将该 Follow Replica 重新加入 ISR 中。

#### Unclean 领导者选举

​        当 ISR 为空时，说明 Leader Replica 所在的 Broker 已经挂掉了，此时需要重新选择Leader Replica。    

- Kafka 把所有不在 ISR 中的副本称为失效副本，失效副本对应的分区也被称为同步失效分区，即 under-replicated 分区。
- 由于这些 Follow Replica 都没有实现与原 Leader Replica 的同步，因此选择这些副本作为 Leader Replica 可能存在数据丢失的问题。这个选举称为 unclean 选举。由Broker端参数 unclean.leader.election.enable 控制是否允许Unclean领导者选举。
- 开启 Unclean 可能会造成数据丢失的问题，但是它使得 Leader Replica 一直存在，因此提高了可用性。因此需要依照具体场景进行选择。

### LEO与HW

**LEO（Log End Offset）**：日志末端位移，代表日志文件中下一条待写入消息的offset，这个offset上实际是没有消息的。不管是leader副本还是follower副本，都有这个值。当leader副本收到生产者的一条消息，LEO通常会自增1，而follower副本需要从leader副本fetch到数据后，才会增加它的LEO，最后leader副本会比较自己的LEO以及满足条件的follower副本上的LEO，选取两者中较小值作为新的HW，来更新自己的HW值。

**HW（High Watermark）**：副本的高水位值，replica中leader副本和follower副本都会有这个值，通过它可以得知副本中已提交或已备份消息的范围，leader副本中的HW，决定了消费者能消费的最新消息能到哪个offset。

#### LEO 和 HW 的更新流程

- LEO
  
  - Leader LEO
    
    Leader LEO 保存在其所在的 Broker 缓存里，当 Leader 副本写入log后，就会更新自己的 LEO
  
  - remote LEO 和 follower LEO： remote LEO 是保存在 Leader 副本上的 follower 副本的 LEO，Leader 副本上包含所有副本的 LEO，同时包括自己本身的 LEO，因此对于 follower LEO，需要分两种情况：
    
    - 如果是 remote LEO，更新前 Leader 需要确认 follower 的 fetch 请求包含 offset，该 offset 就是 follower 副本的 LEO，根据它对 remote LEO 进行更新。如果 fetch 请求在请求队列中排队，则不做更新。因此在 Leader 副本将数据返回给 Follower 副本之前，remote LEO 就已经完成了更新
    - 如果是 Follower LEO，它的更新是在 follower 副本得到 Leader 副本发送的数据并写入到 log 中，就会更新自己的 LEO

- HW
  
  - Leader 副本：只有在以下四种情况下会触发 Leader 副本的 HW 更新
    1. producer 向 Leader 写消息，会尝试更新
    2. Leader 处理 Follower 的 fetch 请求，先读取 log 数据，然后尝试更新  HW
    3. 副本成为 Leader 时，会尝试更新 HW
    4. Broker 崩溃可能波及 Leader 副本，也需要尝试更新
  - follower 副本：更新发生在 follower 副本更新 LEO 之后，一旦 follower 向 log 写完数据，它就会尝试更新 HW 值，比较自己的 LEO 值与 fetch 响应中 Leader 副本的 HW 值，取最小者作为 follower 副本的 HW 值。

![1486105-20200406120618225-1241689514.png](https://i.loli.net/2021/06/21/EepHd8BKm9DG7yI.png)

### 高可靠性 ACK 分析

​    除副本数支持高可靠性之外，也可以设置生产者客户端参数 `request.required.acks`，可选的参数如下：

- acks = 1：这是默认参数，生产者发送消息到 Leader 副本，Leader 副本在成功写入本地日志后会告知生产者已经成功提交。如果此时 ISR 集合的 Follow 副本还没来得及拉取到 Leader 中新写入的消息，而此时 Leader 已经宕机，那么此次发送的消息就会丢失。即生产者只发送一次消息到 Leader 副本，得到 Leader 副本的响应即可。
- acks = -1：生产者将消息发送到 Leader 副本，Leader 副本在写入日志后还要等待 ISR 中的 Follow 副本完全同步才会告知生产者已经成功提交，因此即使此时 Leader 宕机，消息也不会丢失。即所有的消息必须被所有的副本接受后才会认为消息发送成功。
- acks = 0：生产者无需确认消息是否成功发送，而会在发送一条消息之后直接发送下一条消息。这种情况下数据的传输效率最高，但数据可靠性是最低的。

### 高性能页缓存

​    一般磁盘 I/O 的场景有以下四种：

1. 用户调用标准 C 库进行 I/O 操作，数据流为 应用进程 buffer —> C 标准 I/O buffer —> 文件系统页缓存 —> 通过具体文件系统到磁盘
2. 用户直接调用 I/O，数据流为：应用程序 buffer —> 文件系统页缓存—>通过具体文件系统到磁盘
3. 用户打开文件时使用O_DIRECT，绕过页缓存直接读取磁盘
4. 用用户使用用类似 dd 工工具,并使用用 direct 参数,绕过系统 cache与文文件系统直接写磁盘。

![image-20210618095441030.png](https://i.loli.net/2021/06/21/xPs3H4v6FVhugeo.png)

### 零拷贝

一般文件读取并发送到网卡设备中，一般的流程如下图所示：

![image.png](https://i.loli.net/2021/06/21/dkEjKpTbzxgVsfn.png)总共需要进行四次的文件内容复制和两次内核上下文的切换。

而使用零拷贝技术，可以减少这些开销，具体如下图所示：

![image-20210618100025693.png](https://i.loli.net/2021/06/21/uHbcfz8sULwxlvo.png)
